## Goal

Train and interpret transformers on Fibonacci-style sequences, i.e. those that generate a new element from the previous two.

## Results

### 1L, 1H, attention-only transformer

May not have the capacity needed to learn addition properly.

### 1L, 1H, transformer with MLP

TODO

## Misc TODO

- Improve tokenizer
- Wandb integration
- Better data generation
